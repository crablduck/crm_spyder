# åŒ»é™¢å®¢æˆ·ä¿¡æ¯è‡ªåŠ¨åŒ–æ”¶é›†æ–¹æ¡ˆ

## ä¸€ã€æ•°æ®æºæ¢³ç†ä¸æ‰©å±•

### 1.1 å·²çŸ¥æ•°æ®æº
- âœ… ç¦å»ºçœæ”¿åºœé‡‡è´­ç½‘
- âœ… å–æ–¹å…¬å¸å…¬ä¼—å·
- âœ… ä¹°æ–¹åŒ»é™¢å®˜ç½‘å’Œå…¬ä¼—å·

### 1.2 å»ºè®®æ–°å¢æ•°æ®æºï¼ˆé‡è¦ï¼ï¼‰
- ğŸ”¥ **ä¸­å›½æ”¿åºœé‡‡è´­ç½‘** (http://www.ccgp.gov.cn)
- ğŸ”¥ **å„åœ°å¸‚æ”¿åºœé‡‡è´­ç½‘** (å¦‚ï¼šç¦å·å¸‚ã€å¦é—¨å¸‚ã€æ³‰å·å¸‚ç­‰)
- ğŸ”¥ **åŒ»é™¢æ‹›æ ‡å…¬å‘Šæ ** (åŒ»é™¢å®˜ç½‘çš„æ‹›æ ‡é‡‡è´­æ¿å—)
- ğŸ”¥ **åŒ»ç–—å«ç”Ÿä¿¡æ¯åŒ–è¡Œä¸šåª’ä½“**
  - HC3iæ•°å­—åŒ»ç–—ç½‘
  - å¥åº·ç•Œ
  - ä¸­å›½æ•°å­—åŒ»ç–—ç½‘
- ğŸ”¥ **ä¼ä¸šå·¥å•†ä¿¡æ¯ç½‘ç«™** (å¤©çœ¼æŸ¥/ä¼æŸ¥æŸ¥ - æŸ¥è¯¢ä¸­æ ‡å…¬å¸èƒŒæ™¯)
- ğŸ”¥ **åŒ»é™¢ä¿¡æ¯åŒ–æ¡ˆä¾‹åº“**
  - CHIMAå®˜ç½‘(ä¸­å›½åŒ»é™¢åä¼šä¿¡æ¯ä¸“ä¸šå§”å‘˜ä¼š)
  - åŒ»ç–—ä¿¡æ¯åŒ–å‚å•†å®˜ç½‘æ¡ˆä¾‹
- ğŸ”¥ **è¡Œä¸šå±•ä¼šæ–°é—»** (CHINCå¤§ä¼šã€CHIMAå¤§ä¼šæŠ¥é“)

---

## äºŒã€è‡ªåŠ¨åŒ–æ–¹æ¡ˆè®¾è®¡

### æ–¹æ¡ˆæ¶æ„
```
æ•°æ®é‡‡é›†å±‚ â†’ æ•°æ®æ¸…æ´—å±‚ â†’ æ•°æ®åŒ¹é…å±‚ â†’ æ•°æ®å­˜å‚¨å±‚ â†’ æ•°æ®æ›´æ–°å±‚
```

### 2.1 æ ¸å¿ƒçˆ¬è™«æ¨¡å—

#### A. æ”¿åºœé‡‡è´­ç½‘çˆ¬è™« (æœ€é‡è¦ï¼)

**ç›®æ ‡æ•°æ®**ï¼š
- é¡¹ç›®åç§°
- é‡‡è´­å•ä½ï¼ˆåŒ»é™¢åç§°ï¼‰
- ä¸­æ ‡å•ä½ï¼ˆä¾›åº”å•†ï¼‰
- ä¸­æ ‡é‡‘é¢
- é¡¹ç›®å†…å®¹ï¼ˆç³»ç»Ÿåç§°ã€è½¯ç¡¬ä»¶é…ç½®ï¼‰
- ä¸­æ ‡æ—¶é—´
- é¡¹ç›®å‘¨æœŸ

**æŠ€æœ¯æ–¹æ¡ˆ**ï¼š
```python
# æ ¸å¿ƒçˆ¬è™«æ¡†æ¶ï¼ˆåŸºäº Scrapy + Seleniumï¼‰
ç½‘ç«™ç±»å‹ï¼š
1. ç¦å»ºçœæ”¿åºœé‡‡è´­ç½‘: http://ccgp-fujian.gov.cn/
2. ä¸­å›½æ”¿åºœé‡‡è´­ç½‘ç¦å»ºç«™: http://www.ccgp.gov.cn/cggg/dfgg/fjzfcgw/
3. å„åœ°å¸‚é‡‡è´­ç½‘ï¼ˆç¦å·ã€å¦é—¨ç­‰ï¼‰

é‡‡é›†ç­–ç•¥ï¼š
- å…³é”®è¯æœç´¢ï¼šåŒ»é™¢åç§° + ç³»ç»Ÿåç§°ï¼ˆOA/HIS/ç”µå­ç—…å†ç­‰ï¼‰
- æ—¶é—´èŒƒå›´ï¼šè¿‘3-5å¹´
- é‡‡é›†é¢‘ç‡ï¼šæ¯å‘¨ä¸€æ¬¡å¢é‡é‡‡é›†
```

**å…³é”®ä»£ç ç¤ºä¾‹**ï¼š
```python
import scrapy
from selenium import webdriver
import pandas as pd
from datetime import datetime, timedelta

class GovProcurementSpider(scrapy.Spider):
    name = 'gov_procurement'
    
    # åŒ»é™¢åˆ—è¡¨ï¼ˆä»ä½ çš„Excelè¯»å–ï¼‰
    hospitals = [
        'ç¦å·å¤§å­¦é™„å±çœç«‹åŒ»é™¢',
        'å¦é—¨å¤§å­¦é™„å±ç¬¬ä¸€åŒ»é™¢',
        # ... å…¶ä»–åŒ»é™¢
    ]
    
    # ç³»ç»Ÿå…³é”®è¯
    system_keywords = [
        'OA', 'åŠå…¬è‡ªåŠ¨åŒ–',
        'HIS', 'åŒ»é™¢ä¿¡æ¯ç³»ç»Ÿ',
        'ç”µå­ç—…å†', 'EMR',
        'äººäº‹ç³»ç»Ÿ',
        'ç§‘ç ”æ•™å­¦',
        'è´¢åŠ¡ç³»ç»Ÿ',
        'ç‰©æµç³»ç»Ÿ',
        'æŠ¤ç†ç³»ç»Ÿ'
    ]
    
    def start_requests(self):
        base_url = 'http://ccgp-fujian.gov.cn/notice/search'
        
        for hospital in self.hospitals:
            for keyword in self.system_keywords:
                # æ„å»ºæœç´¢URL
                params = {
                    'keyword': f'{hospital} {keyword}',
                    'startDate': (datetime.now() - timedelta(days=365*3)).strftime('%Y-%m-%d'),
                    'endDate': datetime.now().strftime('%Y-%m-%d')
                }
                yield scrapy.Request(
                    url=f"{base_url}?{urlencode(params)}",
                    callback=self.parse,
                    meta={'hospital': hospital, 'system': keyword}
                )
```

#### B. å…¬ä¼—å·æ–‡ç« çˆ¬è™«

**éš¾ç‚¹**ï¼šå¾®ä¿¡å…¬ä¼—å·æœ‰åçˆ¬æœºåˆ¶

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. **æœç‹—å¾®ä¿¡æœç´¢** (weixin.sogou.com)
   - å¯ä»¥æœç´¢å…¬ä¼—å·å†å²æ–‡ç« 
   - ç›¸å¯¹å®¹æ˜“çˆ¬å–
   
2. **æ–°æ¦œ/è¥¿ç“œæ•°æ®** (ä»˜è´¹API)
   - ä¸“ä¸šçš„å…¬ä¼—å·æ•°æ®å¹³å°
   - æä¾›APIæ¥å£

**å…è´¹æ›¿ä»£æ–¹æ¡ˆ**ï¼š
```python
# é€šè¿‡æœç‹—å¾®ä¿¡æœç´¢çˆ¬å–
def search_wechat_articles(hospital_name, system_name):
    """
    æœç´¢åŒ»é™¢å…¬ä¼—å·å‘å¸ƒçš„ç³»ç»Ÿç›¸å…³æ–‡ç« 
    """
    url = f'https://weixin.sogou.com/weixin'
    params = {
        'type': 2,  # 2=æ–‡ç« æœç´¢
        'query': f'{hospital_name} {system_name} ä¸Šçº¿',
        'ie': 'utf8'
    }
    # ä½¿ç”¨ selenium + ä»£ç†æ± 
    # æå–æ–‡ç« æ ‡é¢˜ã€å‘å¸ƒæ—¶é—´ã€å†…å®¹æ‘˜è¦
```

#### C. åŒ»é™¢å®˜ç½‘çˆ¬è™«

**ç›®æ ‡é¡µé¢**ï¼š
- æ–°é—»åŠ¨æ€ï¼ˆç³»ç»Ÿä¸Šçº¿æ–°é—»ï¼‰
- æ‹›æ ‡å…¬å‘Š
- ä¿¡æ¯å…¬å¼€æ ç›®
- ç§‘å®¤ä»‹ç»ï¼ˆäº†è§£ä¸šåŠ¡æµç¨‹ï¼‰

**æŠ€æœ¯è¦ç‚¹**ï¼š
```python
# é€šç”¨åŒ»é™¢å®˜ç½‘ä¿¡æ¯æå–
class HospitalWebSpider:
    def __init__(self, hospital_name, website_url):
        self.hospital_name = hospital_name
        self.url = website_url
        
    def extract_news(self):
        """æå–æ–°é—»åŠ¨æ€ä¸­çš„ç³»ç»Ÿç›¸å…³ä¿¡æ¯"""
        keywords = ['ç³»ç»Ÿä¸Šçº¿', 'ä¿¡æ¯åŒ–å»ºè®¾', 'æ™ºæ…§åŒ»é™¢', 
                   'æ•°å­—åŒ–', 'ç”µå­ç—…å†', 'HIS', 'OA']
        # æœç´¢åŒ…å«å…³é”®è¯çš„æ–°é—»
        
    def extract_procurement(self):
        """æå–æ‹›æ ‡é‡‡è´­ä¿¡æ¯"""
        # å®šä½æ‹›æ ‡å…¬å‘Šæ ç›®
        # æå–è½¯ç¡¬ä»¶é‡‡è´­é¡¹ç›®
```

### 2.2 AIè¾…åŠ©ä¿¡æ¯æå–æ¨¡å—

ä½¿ç”¨ **å¤§è¯­è¨€æ¨¡å‹ (LLM)** è‡ªåŠ¨åˆ†æé‡‡è´­å…¬å‘Šå’Œæ–°é—»å†…å®¹ï¼š

```python
from anthropic import Anthropic

def extract_system_info(text_content, hospital_name):
    """
    ä½¿ç”¨ Claude æå–ç³»ç»Ÿä¿¡æ¯
    """
    client = Anthropic(api_key="your-key")
    
    prompt = f"""
    è¯·ä»ä»¥ä¸‹æ”¿åºœé‡‡è´­å…¬å‘Šæˆ–æ–°é—»å†…å®¹ä¸­æå– {hospital_name} çš„ç³»ç»Ÿä¿¡æ¯ï¼š
    
    éœ€è¦æå–çš„ä¿¡æ¯ï¼š
    1. ç³»ç»Ÿåç§°ï¼ˆOA/HIS/ç”µå­ç—…å†/äººäº‹/è´¢åŠ¡ç­‰ï¼‰
    2. ä¾›åº”å•†åç§°
    3. è½¯ä»¶äº§å“åç§°å’Œç‰ˆæœ¬
    4. ç¡¬ä»¶é…ç½®ï¼ˆæœåŠ¡å™¨ã€å­˜å‚¨ã€ç½‘ç»œè®¾å¤‡ç­‰ï¼‰
    5. é¡¹ç›®é‡‘é¢
    6. å»ºè®¾æ—¶é—´
    7. æŠ€æœ¯æ¶æ„ï¼ˆå¦‚ï¼šB/Sæ¶æ„ã€æ•°æ®åº“ç±»å‹ç­‰ï¼‰
    
    å†…å®¹ï¼š
    {text_content}
    
    è¯·ä»¥JSONæ ¼å¼è¾“å‡ºã€‚
    """
    
    response = client.messages.create(
        model="claude-sonnet-4-5-20250929",
        max_tokens=4096,
        messages=[{"role": "user", "content": prompt}]
    )
    
    return response.content
```

### 2.3 æ•°æ®åŒ¹é…ä¸æ•´åˆæ¨¡å—

```python
import pandas as pd
import json

class DataIntegrator:
    def __init__(self, excel_path):
        self.excel_path = excel_path
        self.hospitals_data = {}
        
    def load_existing_data(self):
        """åŠ è½½ç°æœ‰å®¢æˆ·æ¡£æ¡ˆ"""
        xl = pd.ExcelFile(self.excel_path)
        for sheet_name in xl.sheet_names:
            if sheet_name != 'æ¨¡æ¿':
                df = pd.read_excel(xl, sheet_name=sheet_name, header=None)
                self.hospitals_data[sheet_name] = df
    
    def update_system_info(self, hospital_name, scraped_data):
        """
        æ›´æ–°åŒ»é™¢çš„ç³»ç»Ÿä¿¡æ¯
        """
        # æ‰¾åˆ°å¯¹åº”çš„ sheet
        if hospital_name in self.hospitals_data:
            df = self.hospitals_data[hospital_name]
            
            # å®šä½åˆ°"è½¯ç¡¬ä»¶å»ºè®¾æƒ…å†µ"å•å…ƒæ ¼
            # è‡ªåŠ¨å¡«å……ç³»ç»Ÿä¿¡æ¯
            row_idx = self._find_cell(df, 'è½¯ç¡¬ä»¶å»ºè®¾æƒ…å†µ')
            
            # æ ¼å¼åŒ–ä¿¡æ¯
            system_info = self._format_system_info(scraped_data)
            df.iloc[row_idx, col_idx] = system_info
            
            # ä¿å­˜
            self.hospitals_data[hospital_name] = df
    
    def _format_system_info(self, data):
        """
        æ ¼å¼åŒ–ç³»ç»Ÿä¿¡æ¯
        ä¾‹å¦‚ï¼š
        OAç³»ç»Ÿ: æ³›å¾®OA V9.0 (ä¾›åº”å•†: XXå…¬å¸, å»ºè®¾æ—¶é—´: 2023å¹´, é‡‘é¢: 50ä¸‡)
        HISç³»ç»Ÿ: ä¸œè½¯HIS (ä¾›åº”å•†: ä¸œè½¯é›†å›¢, å»ºè®¾æ—¶é—´: 2020å¹´, é‡‘é¢: 500ä¸‡)
        """
        formatted = []
        for item in data:
            line = f"{item['system_name']}: {item['product']} "
            line += f"(ä¾›åº”å•†: {item['vendor']}, "
            line += f"å»ºè®¾æ—¶é—´: {item['date']}, "
            line += f"é‡‘é¢: {item['amount']})"
            formatted.append(line)
        return '\n'.join(formatted)
    
    def save_to_excel(self):
        """ä¿å­˜å›Excel"""
        with pd.ExcelWriter(self.excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
            for hospital_name, df in self.hospitals_data.items():
                df.to_excel(writer, sheet_name=hospital_name, index=False, header=False)
```

### 2.4 è‡ªåŠ¨åŒ–è¿è¡Œæµç¨‹

```python
# main.py - ä¸»ç¨‹åº
import schedule
import time

def daily_update():
    """æ¯æ—¥è‡ªåŠ¨æ›´æ–°ä»»åŠ¡"""
    print(f"[{datetime.now()}] å¼€å§‹æ•°æ®é‡‡é›†...")
    
    # 1. è¯»å–å®¢æˆ·åˆ—è¡¨
    integrator = DataIntegrator('è¿ç»´å®¢æˆ·æ¡£æ¡ˆ.xlsx')
    integrator.load_existing_data()
    hospitals = list(integrator.hospitals_data.keys())
    
    # 2. çˆ¬å–æ”¿åºœé‡‡è´­ç½‘
    gov_spider = GovProcurementSpider(hospitals)
    gov_data = gov_spider.run()
    
    # 3. çˆ¬å–åŒ»é™¢å®˜ç½‘
    for hospital in hospitals:
        hospital_url = get_hospital_url(hospital)  # éœ€è¦ç»´æŠ¤ä¸€ä¸ªåŒ»é™¢URLå­—å…¸
        web_spider = HospitalWebSpider(hospital, hospital_url)
        web_data = web_spider.extract_all()
        
        # 4. AIæå–ä¿¡æ¯
        extracted_info = []
        for item in (gov_data + web_data):
            info = extract_system_info(item['content'], hospital)
            extracted_info.append(info)
        
        # 5. æ›´æ–°Excel
        integrator.update_system_info(hospital, extracted_info)
    
    # 6. ä¿å­˜
    integrator.save_to_excel()
    print(f"[{datetime.now()}] æ•°æ®æ›´æ–°å®Œæˆï¼")

# è®¾ç½®æ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œ
schedule.every().day.at("02:00").do(daily_update)

# æˆ–è€…æ¯å‘¨ä¸€è¿è¡Œ
# schedule.every().monday.at("02:00").do(daily_update)

while True:
    schedule.run_pending()
    time.sleep(3600)  # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
```

---

## ä¸‰ã€å®Œæ•´é¡¹ç›®ç»“æ„

```
hospital-info-collector/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ hospitals.json          # åŒ»é™¢åˆ—è¡¨å’ŒURLé…ç½®
â”‚   â”œâ”€â”€ system_keywords.json    # ç³»ç»Ÿå…³é”®è¯åº“
â”‚   â””â”€â”€ settings.py             # å…¨å±€é…ç½®
â”œâ”€â”€ spiders/
â”‚   â”œâ”€â”€ gov_procurement.py      # æ”¿åºœé‡‡è´­ç½‘çˆ¬è™«
â”‚   â”œâ”€â”€ wechat_articles.py      # å…¬ä¼—å·æ–‡ç« çˆ¬è™«
â”‚   â””â”€â”€ hospital_website.py     # åŒ»é™¢å®˜ç½‘çˆ¬è™«
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ ai_extractor.py         # AIä¿¡æ¯æå–
â”‚   â”œâ”€â”€ data_cleaner.py         # æ•°æ®æ¸…æ´—
â”‚   â””â”€â”€ data_integrator.py      # æ•°æ®æ•´åˆ
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ proxy_pool.py           # ä»£ç†æ± ç®¡ç†
â”‚   â”œâ”€â”€ excel_handler.py        # Excelè¯»å†™
â”‚   â””â”€â”€ logger.py               # æ—¥å¿—è®°å½•
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # åŸå§‹é‡‡é›†æ•°æ®
â”‚   â”œâ”€â”€ processed/              # å¤„ç†åæ•°æ®
â”‚   â””â”€â”€ è¿ç»´å®¢æˆ·æ¡£æ¡ˆ.xlsx       # æœ€ç»ˆè¾“å‡º
â”œâ”€â”€ logs/                       # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ main.py                     # ä¸»ç¨‹åº
â”œâ”€â”€ requirements.txt            # ä¾èµ–åŒ…
â””â”€â”€ README.md                   # è¯´æ˜æ–‡æ¡£
```

---

## å››ã€å…³é”®ä¾èµ–åŒ…

```txt
# requirements.txt
scrapy==2.11.0
selenium==4.15.0
pandas==2.1.0
openpyxl==3.1.2
anthropic==0.7.0
beautifulsoup4==4.12.2
requests==2.31.0
schedule==1.2.0
fake-useragent==1.4.0
redis==5.0.0  # ç”¨äºå»é‡
pymongo==4.5.0  # å¯é€‰ï¼šå­˜å‚¨åˆ°æ•°æ®åº“
```

---

## äº”ã€æ•°æ®é‡‡é›†ä¼˜å…ˆçº§å»ºè®®

### é«˜ä¼˜å…ˆçº§ï¼ˆå¿…é¡»å®ç°ï¼‰
1. âœ… **ç¦å»ºçœæ”¿åºœé‡‡è´­ç½‘** - æœ€æƒå¨çš„æ•°æ®æº
2. âœ… **åŒ»é™¢å®˜ç½‘æ–°é—»** - ç¬¬ä¸€æ‰‹ä¿¡æ¯
3. âœ… **åŒ»é™¢æ‹›æ ‡å…¬å‘Š** - å³å°†å®æ–½çš„é¡¹ç›®

### ä¸­ä¼˜å…ˆçº§ï¼ˆå»ºè®®å®ç°ï¼‰
4. â­ **ä¸­å›½æ”¿åºœé‡‡è´­ç½‘** - è¡¥å……æ•°æ®
5. â­ **åŒ»é™¢å…¬ä¼—å·** - å®£ä¼ æ€§è´¨çš„ç³»ç»Ÿä¸Šçº¿ä¿¡æ¯
6. â­ **ä¾›åº”å•†å…¬ä¼—å·** - æ¡ˆä¾‹åˆ†äº«

### ä½ä¼˜å…ˆçº§ï¼ˆå¯é€‰ï¼‰
7. ğŸ”¸ **è¡Œä¸šåª’ä½“æŠ¥é“** - æ–°é—»ç¨¿
8. ğŸ”¸ **CHIMAæ¡ˆä¾‹åº“** - ä¼˜ç§€æ¡ˆä¾‹
9. ğŸ”¸ **å±•ä¼šæ–°é—»** - è¡Œä¸šåŠ¨æ€

---

## å…­ã€æ³•å¾‹åˆè§„å»ºè®®

âš ï¸ **é‡è¦æç¤º**ï¼š
1. **éµå®ˆ robots.txt** - æ£€æŸ¥ç½‘ç«™æ˜¯å¦å…è®¸çˆ¬å–
2. **æ§åˆ¶çˆ¬å–é¢‘ç‡** - é¿å…å¯¹æœåŠ¡å™¨é€ æˆå‹åŠ›ï¼ˆå»ºè®® 3-5ç§’/è¯·æ±‚ï¼‰
3. **ä½¿ç”¨ä»£ç†IPæ± ** - é¿å…è¢«å°
4. **æ•°æ®ä»…ä¾›å†…éƒ¨ä½¿ç”¨** - ä¸è¦å…¬å¼€ä¼ æ’­
5. **å…¬ä¼—å·æ•°æ®** - å»ºè®®ä½¿ç”¨å®˜æ–¹APIæˆ–ä»˜è´¹å¹³å°

---

## ä¸ƒã€æ•°æ®è´¨é‡æ§åˆ¶

### 7.1 æ•°æ®éªŒè¯è§„åˆ™
```python
def validate_system_info(data):
    """éªŒè¯é‡‡é›†çš„æ•°æ®è´¨é‡"""
    required_fields = ['system_name', 'vendor', 'amount']
    
    # å¿…å¡«å­—æ®µæ£€æŸ¥
    for field in required_fields:
        if not data.get(field):
            return False, f"ç¼ºå°‘å­—æ®µ: {field}"
    
    # é‡‘é¢æ ¼å¼æ£€æŸ¥
    if not re.match(r'^\d+(\.\d+)?[ä¸‡å…ƒ]', data['amount']):
        return False, "é‡‘é¢æ ¼å¼é”™è¯¯"
    
    # æ—¶é—´æ ¼å¼æ£€æŸ¥
    if not re.match(r'\d{4}å¹´', data.get('date', '')):
        return False, "æ—¶é—´æ ¼å¼é”™è¯¯"
    
    return True, "éªŒè¯é€šè¿‡"
```

### 7.2 äººå·¥å®¡æ ¸æœºåˆ¶
```python
def flag_for_review(data, confidence_score):
    """
    æ ‡è®°éœ€è¦äººå·¥å®¡æ ¸çš„æ•°æ®
    ç½®ä¿¡åº¦ < 0.7 çš„æ•°æ®éœ€è¦äººå·¥ç¡®è®¤
    """
    if confidence_score < 0.7:
        # å°†æ•°æ®å†™å…¥å¾…å®¡æ ¸é˜Ÿåˆ—
        review_queue.append({
            'hospital': data['hospital'],
            'content': data['raw_content'],
            'extracted': data['extracted_info'],
            'confidence': confidence_score,
            'timestamp': datetime.now()
        })
```

---

## å…«ã€æˆæœ¬é¢„ä¼°

### å…è´¹æ–¹æ¡ˆï¼ˆæ¨èèµ·æ­¥ï¼‰
- çˆ¬è™«æœåŠ¡å™¨: 0å…ƒï¼ˆæœ¬åœ°è¿è¡Œæˆ–ä½¿ç”¨å·²æœ‰æœåŠ¡å™¨ï¼‰
- ä»£ç†IP: 50-100å…ƒ/æœˆï¼ˆæŸäº›å…è´¹ä»£ç†æ± ï¼‰
- Claude API: çº¦100-300å…ƒ/æœˆï¼ˆæ ¹æ®ä½¿ç”¨é‡ï¼‰
- **æ€»è®¡**: 150-400å…ƒ/æœˆ

### è¿›é˜¶æ–¹æ¡ˆ
- äº‘æœåŠ¡å™¨: 100å…ƒ/æœˆ
- ä»˜è´¹ä»£ç†IP: 200-500å…ƒ/æœˆ
- å…¬ä¼—å·æ•°æ®API (æ–°æ¦œ): 500-1000å…ƒ/æœˆ
- Claude API: 300-500å…ƒ/æœˆ
- **æ€»è®¡**: 1100-2100å…ƒ/æœˆ

---

## ä¹ã€å®æ–½æ—¶é—´è¡¨

### ç¬¬ä¸€é˜¶æ®µï¼ˆ1-2å‘¨ï¼‰ï¼šåŸºç¡€æ¡†æ¶æ­å»º
- âœ… æ­å»ºçˆ¬è™«æ¡†æ¶
- âœ… å®ç°æ”¿åºœé‡‡è´­ç½‘çˆ¬è™«ï¼ˆæœ€æ ¸å¿ƒï¼‰
- âœ… å®ç°æ•°æ®å­˜å‚¨åˆ°ExcelåŠŸèƒ½

### ç¬¬äºŒé˜¶æ®µï¼ˆ2-3å‘¨ï¼‰ï¼šåŠŸèƒ½å®Œå–„
- âœ… æ·»åŠ åŒ»é™¢å®˜ç½‘çˆ¬è™«
- âœ… é›†æˆAIä¿¡æ¯æå–
- âœ… å®ç°è‡ªåŠ¨æ›´æ–°æœºåˆ¶

### ç¬¬ä¸‰é˜¶æ®µï¼ˆ1-2å‘¨ï¼‰ï¼šä¼˜åŒ–ä¸æµ‹è¯•
- âœ… æ•°æ®è´¨é‡éªŒè¯
- âœ… å¼‚å¸¸å¤„ç†
- âœ… æ€§èƒ½ä¼˜åŒ–

---

## åã€å¿«é€Ÿå¯åŠ¨ç¤ºä¾‹

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. é…ç½®
cp config/settings.example.py config/settings.py
# ç¼–è¾‘ settings.pyï¼Œå¡«å…¥ Claude API Key ç­‰é…ç½®

# 3. åˆå§‹åŒ–æ•°æ®åº“ï¼ˆå¯é€‰ï¼‰
python init_db.py

# 4. è¿è¡Œå•æ¬¡é‡‡é›†æµ‹è¯•
python main.py --mode test --hospital "ç¦å·å¤§å­¦é™„å±çœç«‹åŒ»é™¢"

# 5. å¯åŠ¨å®šæ—¶ä»»åŠ¡
python main.py --mode schedule
```

---

## åä¸€ã€ç›‘æ§ä¸å‘Šè­¦

```python
# ç›‘æ§æ¨¡å—
import smtplib
from email.mime.text import MIMEText

class Monitor:
    def __init__(self):
        self.success_count = 0
        self.fail_count = 0
        
    def send_alert(self, message):
        """å‘é€å‘Šè­¦é‚®ä»¶"""
        msg = MIMEText(message)
        msg['Subject'] = 'æ•°æ®é‡‡é›†å¼‚å¸¸å‘Šè­¦'
        msg['From'] = 'system@company.com'
        msg['To'] = 'admin@company.com'
        
        # å‘é€é‚®ä»¶
        
    def daily_report(self):
        """æ¯æ—¥æ•°æ®æŠ¥å‘Š"""
        report = f"""
        æ•°æ®é‡‡é›†æ—¥æŠ¥ - {datetime.now().date()}
        
        æˆåŠŸé‡‡é›†: {self.success_count} æ¡
        å¤±è´¥: {self.fail_count} æ¡
        æ–°å¢åŒ»é™¢ç³»ç»Ÿä¿¡æ¯: {self.new_systems_count} ä¸ª
        æ›´æ–°åŒ»é™¢: {len(self.updated_hospitals)} å®¶
        """
        self.send_alert(report)
```

---

## åäºŒã€é™„åŠ å»ºè®®

### 12.1 å»ºç«‹ç³»ç»ŸçŸ¥è¯†åº“
å»ºè®®å»ºç«‹ä¸€ä¸ª **åŒ»ç–—ä¿¡æ¯ç³»ç»Ÿäº§å“çŸ¥è¯†åº“**ï¼š
```json
{
  "OAç³»ç»Ÿ": {
    "ä¸»æµäº§å“": ["æ³›å¾®OA", "è‡´è¿œOA", "è“å‡ŒOA", "åå¤©åŠ¨åŠ›OA"],
    "å…³é”®å­—": ["åŠå…¬è‡ªåŠ¨åŒ–", "ååŒåŠå…¬", "æµç¨‹ç®¡ç†"],
    "ä¸»è¦ä¾›åº”å•†": ["æ³›å¾®ç½‘ç»œ", "è‡´è¿œäº’è”", "è“å‡Œè½¯ä»¶"]
  },
  "HISç³»ç»Ÿ": {
    "ä¸»æµäº§å“": ["ä¸œè½¯HIS", "å«å®å¥åº·", "åˆ›ä¸šæ…§åº·", "å˜‰å’Œç¾åº·"],
    "å…³é”®å­—": ["åŒ»é™¢ä¿¡æ¯ç³»ç»Ÿ", "é—¨è¯Šç³»ç»Ÿ", "ä½é™¢ç³»ç»Ÿ"],
    "ä¸»è¦ä¾›åº”å•†": ["ä¸œè½¯é›†å›¢", "å«å®å¥åº·", "åˆ›ä¸šæ…§åº·"]
  }
}
```

### 12.2 ç«å“è¿½è¸ª
åŒæ­¥é‡‡é›†ç«äº‰å¯¹æ‰‹çš„é¡¹ç›®ä¿¡æ¯ï¼š
- åœ¨æ”¿åºœé‡‡è´­ç½‘æœç´¢ç«äº‰å¯¹æ‰‹çš„ä¸­æ ‡é¡¹ç›®
- äº†è§£ä»–ä»¬åœ¨å“ªäº›åŒ»é™¢æœ‰ä¸šåŠ¡
- åˆ†æä»–ä»¬çš„äº§å“å’Œå®šä»·ç­–ç•¥

### 12.3 æ•°æ®å¯è§†åŒ–
å»ºç«‹æ•°æ®çœ‹æ¿ï¼š
```python
# ä½¿ç”¨ Streamlit æˆ– Dash æ„å»ºå¯è§†åŒ–ç•Œé¢
import streamlit as st
import plotly.express as px

st.title("åŒ»é™¢å®¢æˆ·ä¿¡æ¯çœ‹æ¿")

# æ˜¾ç¤ºç³»ç»Ÿè¦†ç›–æƒ…å†µ
fig = px.bar(df, x='hospital', y='system_count', title='å„åŒ»é™¢ç³»ç»Ÿæ•°é‡')
st.plotly_chart(fig)

# æ˜¾ç¤ºä¾›åº”å•†åˆ†å¸ƒ
fig2 = px.pie(df, names='vendor', title='ä¾›åº”å•†å¸‚åœºä»½é¢')
st.plotly_chart(fig2)
```

---

## æ€»ç»“

è¿™å¥—æ–¹æ¡ˆçš„æ ¸å¿ƒä¼˜åŠ¿ï¼š
1. âœ… **è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜** - å‡å°‘90%çš„äººå·¥æœé›†æ—¶é—´
2. âœ… **æ•°æ®æ¥æºæƒå¨** - æ”¿åºœé‡‡è´­ç½‘æ•°æ®æœ€å¯é 
3. âœ… **AIè¾…åŠ©æå–** - è‡ªåŠ¨ç†è§£å’Œç»“æ„åŒ–éç»“æ„åŒ–æ–‡æœ¬
4. âœ… **æŒç»­æ›´æ–°** - å®šæ—¶ä»»åŠ¡ä¿æŒæ•°æ®æ–°é²œåº¦
5. âœ… **å¯æ‰©å±•æ€§å¼º** - æ˜“äºæ·»åŠ æ–°çš„æ•°æ®æº

**æœ€å¿«å¯åŠ¨è·¯å¾„**ï¼š
1. å…ˆå®ç°æ”¿åºœé‡‡è´­ç½‘çˆ¬è™«ï¼ˆ2-3å¤©ï¼‰
2. å†æ·»åŠ åŒ»é™¢å®˜ç½‘çˆ¬è™«ï¼ˆ1-2å¤©ï¼‰
3. æœ€åé›†æˆAIæå–ï¼ˆ1å¤©ï¼‰

é¢„è®¡ **1-2å‘¨** å³å¯ä¸Šçº¿åŸºç¡€ç‰ˆæœ¬ï¼
